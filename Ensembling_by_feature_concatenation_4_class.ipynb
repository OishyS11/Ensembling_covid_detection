{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensembling by feature concatenation 4 class.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWFr0o9-PWjk"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By_S3IvJPfks"
      },
      "source": [
        " \n",
        "# General libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        " \n",
        "# Deep learning libraries\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, LeakyReLU, Activation, Lambda, GlobalAveragePooling2D, DepthwiseConv2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import Add, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "import tensorflow as tf\n",
        " \n",
        "# Setting seeds for reproducibility\n",
        "seed = 232\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBHWct34x2ZG"
      },
      "source": [
        "### **Getting Data from different folds (5-fold cross validation scheme has been employed)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DCyVt-iPhib"
      },
      "source": [
        "input_path = '/content/drive/My Drive/four_class/Fold 2/' #Change it as necessary, This is the base path for data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KOeKsm0Pk9w"
      },
      "source": [
        "# Hyperparameters\n",
        "img_dims = 227\n",
        "epochs = 50\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAc-YDRHyiFW"
      },
      "source": [
        "## **Pre-processing of images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8edgYRz0PlNR"
      },
      "source": [
        "X_train = []\n",
        "X_test = []\n",
        "y_train = []\n",
        "y_test = []\n",
        "\n",
        "for tt in ['train', 'test']:\n",
        "  for cond in ['/COVID19/', '/NORMAL/','/Bacterial/','/Viral/']:\n",
        "    for img_name in os.listdir(input_path+tt+cond):\n",
        "      img = cv2.imread(input_path+tt+cond+img_name, 0)\n",
        "      try:\n",
        "        img = cv2.resize(img, (img_dims, img_dims))\n",
        "      except:\n",
        "        print(img_name)\n",
        "      \n",
        "      #lbp_img = local_binary_pattern(img, P=8, R=8, method='uniform')/255.0\n",
        "      img = np.dstack([img, img, img])  #Feinting color image channel\n",
        "      img = img.astype('float32') / 255.0\n",
        "      #img = img/255.0\n",
        "      if tt=='train':\n",
        "        X_train.append(img)\n",
        "        \n",
        "        if cond=='/COVID19/':\n",
        "          label=0\n",
        "          y_train.append(label)\n",
        "        elif cond=='/NORMAL/':\n",
        "          label=1\n",
        "          y_train.append(label)\n",
        "        elif cond=='/Bacterial/':\n",
        "          label=2\n",
        "          y_train.append(label)\n",
        "        else:\n",
        "          label=3\n",
        "          y_train.append(label)\n",
        "      else:\n",
        "        X_test.append(img)\n",
        "        \n",
        "        if cond=='/COVID19/':\n",
        "          label=0\n",
        "          y_test.append(label)\n",
        "        elif cond=='/NORMAL/':\n",
        "          label=1\n",
        "          y_test.append(label)\n",
        "        elif cond=='/Bacterial/':\n",
        "          label=2\n",
        "          y_test.append(label)\n",
        "        else:\n",
        "          label=3\n",
        "          y_test.append(label)\n",
        "\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48YyeA5vMGzB"
      },
      "source": [
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKXTpQEKMDJ0"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "print(y_train_cat.shape, y_test_cat.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P82XpvoPya7"
      },
      "source": [
        "## **First Model to Use (MobileNet)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy_dyXGDPom3"
      },
      "source": [
        "##########MODEL DESCRIPTION GOES HERE ###############\n",
        "########### THIS IS MobileNet ########## \n",
        " \n",
        "num_classes=4\n",
        "\n",
        "IMAGE_SIZE = [227,227]\n",
        "inceptionv3 = tf.keras.applications.MobileNet(input_shape = IMAGE_SIZE + [3], weights = 'imagenet',include_top = False,pooling='avg')\n",
        "\n",
        "\n",
        "for layer in inceptionv3.layers[:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "#x = GlobalAveragePooling2D(inceptionv3.output)\n",
        "#x = Flatten()(inceptionv3.output)\n",
        "x=Dense(256,activation='relu')(inceptionv3.output)\n",
        "x=Dense(128,activation='relu')(x)\n",
        "x=Dropout(.2)(x)\n",
        "#x=Dense(256,activation='relu')(x)\n",
        "prediction = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model1 = Model(inputs=inceptionv3.input,outputs=prediction)\n",
        "opt=Adam(learning_rate=0.0001)\n",
        "\n",
        "model1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "weight_path = '/content/drive/My Drive/Results/Weight/4 class mobilenet weight/4 class mobilenet fold 2.h5'###### Here weights of 1st viral vs bacterial model will be loaded\n",
        "model1.load_weights(weight_path)\n",
        " \n",
        "model_first = Model(model1.inputs, model1.layers[-5].output)# Here, the final dense layer is layer -1, the dropout before that is -2, then -3 and -4 and Flatten layer is -5. Take what you need.\n",
        "X_train_first = model_first.predict(X_train)\n",
        "X_test_first = model_first.predict(X_test)\n",
        " \n",
        "######################### This is where we will save the predictions ################################\n",
        "save_path = '/content/drive/My Drive/'##########################\n",
        "np.save(save_path+'Train First Model.npy', X_train_first)\n",
        "np.save(save_path+'Test First Model.npy', X_test_first)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frygnry_n2_P"
      },
      "source": [
        "## **Second Model to Use (InceptionV3)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdTyd2uZsbqu"
      },
      "source": [
        "##########MODEL DESCRIPTION GOES HERE ###############\n",
        "########### THIS IS Inception ########## \n",
        " \n",
        "\n",
        "num_classes=4\n",
        "\n",
        "IMAGE_SIZE = [227,227]\n",
        "inceptionv3 = tf.keras.applications.InceptionV3(input_shape = IMAGE_SIZE + [3], weights = 'imagenet',include_top = False,pooling='avg')\n",
        "\n",
        "\n",
        "for layer in inceptionv3.layers[:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "#x = GlobalAveragePooling2D(inceptionv3.output)\n",
        "#x = Flatten()(inceptionv3.output)\n",
        "x=Dense(256,activation='relu')(inceptionv3.output)\n",
        "x=Dense(128,activation='relu')(x)\n",
        "x=Dropout(.2)(x)\n",
        "#x=Dense(256,activation='relu')(x)\n",
        "prediction = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model2 = Model(inputs=inceptionv3.input,outputs=prediction)\n",
        "opt=Adam(learning_rate=0.0001)\n",
        "\n",
        "model2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "weight_path = '/content/drive/My Drive/Results/Weight/4 class inception weight/4 class inception fold 2.h5'###### Here weights of 1st viral vs bacterial model will be loaded\n",
        "model2.load_weights(weight_path)\n",
        " \n",
        "model_second = Model(model2.inputs, model2.layers[-5].output)# Here, the final dense layer is layer -1, the dropout before that is -2, then -3 and -4 and Flatten layer is -5. Take what you need.\n",
        "X_train_second = model_second.predict(X_train)\n",
        "X_test_second = model_second.predict(X_test)\n",
        " \n",
        "######################### This is where we will save the predictions ################################\n",
        "save_path = '/content/drive/My Drive/'##########################\n",
        "np.save(save_path+'Train Second Model.npy', X_train_second)\n",
        "np.save(save_path+'Test Second Model.npy', X_test_second)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj-U1QTGstJ3"
      },
      "source": [
        "## **Third Model to Use(Densenet201)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azxkf7PwsoYT"
      },
      "source": [
        "##########MODEL DESCRIPTION GOES HERE ###############\n",
        "########### THIS IS DenseNet201 ########## \n",
        "\n",
        "num_classes=4\n",
        "\n",
        "IMAGE_SIZE = [227,227]\n",
        "inceptionv3 = tf.keras.applications.DenseNet201(input_shape = IMAGE_SIZE + [3], weights = 'imagenet',include_top = False,pooling='avg')\n",
        "\n",
        "\n",
        "for layer in inceptionv3.layers[:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "x=Dense(256,activation='relu')(inceptionv3.output)\n",
        "x=Dense(128,activation='relu')(x)\n",
        "x=Dropout(.2)(x)\n",
        "#x=Dense(256,activation='relu')(x)\n",
        "prediction = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model3 = Model(inputs=inceptionv3.input,outputs=prediction)\n",
        "opt=Adam(learning_rate=0.0001)\n",
        "\n",
        "model3.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "weight_path = '/content/drive/My Drive/Results/Weight/4 class densenet weight/4 class Densenet fold 2.h5'###### Here weights of 1st viral vs bacterial model will be loaded\n",
        "model3.load_weights(weight_path)\n",
        " \n",
        "model_third = Model(model3.inputs, model3.layers[-5].output)# Here, the final dense layer is layer -1, the dropout before that is -2, then -3 and -4 and Flatten layer is -5. Take what you need.\n",
        "X_train_third = model_third.predict(X_train)\n",
        "X_test_third = model_third.predict(X_test)\n",
        " \n",
        "######################### This is where we will save the predictions ################################\n",
        "save_path = '/content/drive/My Drive/'##########################\n",
        "np.save(save_path+'Train Third Model.npy', X_train_third)\n",
        "np.save(save_path+'Test Third Model.npy', X_test_third)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgFrJ209tJDg"
      },
      "source": [
        "## **Fourth Model to Use(Xception)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRnHbBtMsp38"
      },
      "source": [
        "##########MODEL DESCRIPTION GOES HERE ###############\n",
        "########### THIS IS Xception ########## \n",
        "\n",
        "num_classes=4\n",
        "\n",
        "IMAGE_SIZE = [227,227]\n",
        "inceptionv3 = tf.keras.applications.Xception(input_shape = IMAGE_SIZE + [3], weights = 'imagenet',include_top = False,pooling='avg')\n",
        "\n",
        "\n",
        "for layer in inceptionv3.layers[:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "#x = GlobalAveragePooling2D(inceptionv3.output)\n",
        "#x = Flatten()(inceptionv3.output)\n",
        "x=Dense(256,activation='relu')(inceptionv3.output)\n",
        "x=Dense(128,activation='relu')(x)\n",
        "x=Dropout(.2)(x)\n",
        "#x=Dense(256,activation='relu')(x)\n",
        "prediction = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model4 = Model(inputs=inceptionv3.input,outputs=prediction)\n",
        "opt=Adam(learning_rate=0.0001)\n",
        "\n",
        "model4.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "weight_path = '/content/drive/My Drive/Results/Weight/4 class xception weight/4 class xception fold 2.h5'###### Here weights of 1st viral vs bacterial model will be loaded\n",
        "model4.load_weights(weight_path)\n",
        " \n",
        "model_fourth = Model(model4.inputs, model4.layers[-5].output)# Here, the final dense layer is layer -1, the dropout before that is -2, then -3 and -4 and Flatten layer is -5. Take what you need.\n",
        "X_train_fourth = model_fourth.predict(X_train)\n",
        "X_test_fourth = model_fourth.predict(X_test)\n",
        " \n",
        "######################### This is where we will save the predictions ################################\n",
        "save_path = '/content/drive/My Drive/'##########################\n",
        "np.save(save_path+'Train Fourth Model.npy', X_train_fourth)\n",
        "np.save(save_path+'Test Fourth Model.npy', X_test_fourth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBblxHFZzvyO"
      },
      "source": [
        "## **Fifth Model to Use (DenseNet121)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjVsOqZ9zXgg"
      },
      "source": [
        "##########MODEL DESCRIPTION GOES HERE ###############\n",
        "########### THIS IS DenseNet121 ########## \n",
        "\n",
        "num_classes=4\n",
        "\n",
        "IMAGE_SIZE = [227,227]\n",
        "inceptionv3 = tf.keras.applications.DenseNet121(input_shape = IMAGE_SIZE + [3], weights = 'imagenet',include_top = False,pooling='avg')\n",
        "\n",
        "\n",
        "for layer in inceptionv3.layers[:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "#x = GlobalAveragePooling2D(inceptionv3.output)\n",
        "#x = Flatten()(inceptionv3.output)\n",
        "x=Dense(256,activation='relu')(inceptionv3.output)\n",
        "x=Dense(128,activation='relu')(x)\n",
        "x=Dropout(.2)(x)\n",
        "#x=Dense(256,activation='relu')(x)\n",
        "prediction = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model5 = Model(inputs=inceptionv3.input,outputs=prediction)\n",
        "opt=Adam(learning_rate=0.0001)\n",
        "\n",
        "model5.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "weight_path = '/content/drive/My Drive/Results/Weight/4 class densenet121 weight/4 class densenet121 fold 2.h5'###### Here weights of 1st viral vs bacterial model will be loaded\n",
        "model5.load_weights(weight_path)\n",
        " \n",
        "model_fifth = Model(model5.inputs, model5.layers[-5].output)# Here, the final dense layer is layer -1, the dropout before that is -2, then -3 and -4 and Flatten layer is -5. Take what you need.\n",
        "X_train_fifth = model_fifth.predict(X_train)\n",
        "X_test_fifth = model_fifth.predict(X_test)\n",
        " \n",
        "######################### This is where we will save the predictions ################################\n",
        "save_path = '/content/drive/My Drive/'##########################\n",
        "np.save(save_path+'Train Fifth Model.npy', X_train_fifth)\n",
        "np.save(save_path+'Test Fifth Model.npy', X_test_fifth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92ShsKCDRp7o"
      },
      "source": [
        "X_train1 = np.concatenate((X_train_first, X_train_second,X_train_third,X_train_fourth,X_train_fifth), axis=1)\n",
        "X_test1 = np.concatenate((X_test_first, X_test_second,X_test_third,X_test_fourth,X_test_fifth), axis=1)\n",
        "\n",
        "models = Sequential()\n",
        "models.add(Dense(256, activation='relu', input_shape=(X_train1.shape[1], )))\n",
        "models.add(Dense(128, activation='relu'))\n",
        "models.add(Dropout(0.2))\n",
        "models.add(Dense(4, activation='softmax'))\n",
        "opt=Adam(learning_rate=0.0001)\n",
        "models.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "models.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTyD33UPTARa"
      },
      "source": [
        "model_name = '4 class Ensemble Fold2'#########################################################################\n",
        "\n",
        "weight_save_path = '/content/drive/My Drive/Results/Weight/'\n",
        "\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=2, verbose=2, mode='max', min_lr=0.00001)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3, mode='min')\n",
        "checkpoint = ModelCheckpoint(weight_save_path+model_name+'.h5', monitor='val_accuracy', save_best_only=True, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwuJGWPOTL8u"
      },
      "source": [
        "# Fitting the model \n",
        "hist = models.fit(X_train1,y_train_cat,epochs=epochs, batch_size=16, validation_split=0.2, callbacks=[checkpoint, lr_reduce])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c4xWnC7TbUP"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate(['accuracy', 'loss']):\n",
        "    ax[i].plot(hist.history[met])\n",
        "    ax[i].plot(hist.history['val_' + met])\n",
        "    ax[i].set_title('Model {}'.format(met))\n",
        "    ax[i].set_xlabel('epochs')\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend(['train', 'val'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmOPZ5YJTew6"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = models.predict(X_test1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "print(np.unique(y_pred_bool))\n",
        "\n",
        "\n",
        "report = classification_report(y_test, y_pred_bool, output_dict=True)\n",
        "print(classification_report(y_test, y_pred_bool))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8yP2Y8RTgn8"
      },
      "source": [
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "############## Make Sure to Change this ####################\n",
        "plot_save_path = '/content/drive/My Drive/Results/ModelPlot/'\n",
        "hist_save_path = '/content/drive/My Drive/Results/History/'\n",
        "result_save_path = '/content/drive/My Drive/Results/Result/'\n",
        "confusion_matrix_save_path = '/content/drive/My Drive/Results/Confusion Matrix/'\n",
        "\n",
        "\n",
        "hist_df = pd.DataFrame(hist.history)\n",
        "hist_csv_file = hist_save_path+model_name+'_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "plot_model(models, plot_save_path+model_name+'.png', show_shapes=True)\n",
        "\n",
        "result_df = report\n",
        "result_df = pd.DataFrame(result_df).transpose()\n",
        "\n",
        "print(result_df)\n",
        "\n",
        "result_df.to_csv(result_save_path+model_name+'_result.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSuCKcRITiPh"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from seaborn import heatmap\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "preds = np.argmax(models.predict(X_test1), axis=1)\n",
        "acc = accuracy_score(y_test, np.round(preds))*100\n",
        "cm = confusion_matrix(y_test, np.round(preds))\n",
        "cm_norm = confusion_matrix(y_test, np.round(preds), normalize='true')\n",
        "#tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print('CONFUSION MATRIX ------------------')\n",
        "\n",
        "ax = heatmap(cm, cmap='Blues', linecolor='lightblue',linewidths=.5,annot=True,annot_kws={'size': 12,\"weight\": \"bold\"}, xticklabels=['BACTERIAL PNEUMONIA','COVID19', 'NORMAL','VIRAL PNEUMONIA'], yticklabels=['BACTERIAL PNEUMONIA','COVID19', 'NORMAL','VIRAL PNEUMONIA'], square=True, fmt='d')\n",
        "\n",
        "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 12)\n",
        "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 12,rotation=0)\n",
        "\n",
        "plt.savefig(confusion_matrix_save_path+model_name+'.png',dpi=500)\n",
        "plt.show()\n",
        "\n",
        "ax = heatmap(cm_norm, cmap='Blues', annot=True,linecolor='lightblue',linewidths=.5,annot_kws={'size': 12,\"weight\": \"bold\"}, xticklabels=['BACTERIAL PNEUMONIA','COVID19', 'NORMAL','VIRAL PNEUMONIA'], yticklabels=['BACTERIAL PNEUMONIA','COVID19', 'NORMAL','VIRAL PNEUMONIA'], square=True, fmt='.2f')\n",
        "\n",
        "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 12)\n",
        "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 12,rotation=0)\n",
        "\n",
        "plt.savefig(confusion_matrix_save_path+model_name+'_normalized.png',dpi=500)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}